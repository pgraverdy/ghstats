{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a595fab-ad61-49d8-b804-bb4de95ca5f6",
   "metadata": {},
   "source": [
    "# Github Project Statistics\n",
    "\n",
    "\n",
    "\n",
    "A notebook for generating a report on various git and github statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c4e7c-48e9-4c94-b874-f901d0d37494",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install markdown-pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b929a-c350-4fdc-92e1-fe29cd0bf98d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install requests pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3789357-99e9-4e9a-91e4-aa2d2348a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyGithub gitpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6475c7-8975-44c5-b30e-fcaf8fd649ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install dataframe-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5800e49e-c1fb-4407-88a1-70b7585ce780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from github import Github\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "\n",
    "from git import Repo\n",
    "import ast\n",
    "import dataframe_image as dfi\n",
    "\n",
    "import os\n",
    "\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4a787-2940-45a9-a63f-af38b8ce8fdc",
   "metadata": {},
   "source": [
    "## Github and general configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90083075-0814-4b58-8dbd-51f496998fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use to the your env variables with the correct value (but do not commit the changes)\n",
    "# %set_env GHSTATS_LOGIN 'xxxx'\n",
    "# %set_env GHSTATS_TOKEN 'xxxx'\n",
    "\n",
    "# show the values that will be used (clear the cell before commit)\n",
    "# print(os.environ.get('GHSTATS_LOGIN'))\n",
    "# print(os.environ.get('GHSTATS_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8360d9-23f0-4bdb-8d92-8a8cacb40289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials to connect to github and retrie information\n",
    "owner = os.environ.get('GHSTATS_LOGIN')\n",
    "access_token = os.environ.get('GHSTATS_TOKEN')\n",
    "\n",
    "# where the code for this notebook is hosted\n",
    "notebook_url = \"https://github.com/pgraverdy/gh_stats\"\n",
    "\n",
    "# used to store filenames for exported images to be used in the final report\n",
    "image_filenames = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a665d-4d9b-42d8-aa73-f19775cab4cd",
   "metadata": {},
   "source": [
    "## Projects configuration\n",
    "\n",
    "Select the project and run the appropriate cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c844d17-d816-41e9-acee-21225a00ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pinocchio\n",
    "\n",
    "organisation = 'stack-of-tasks'\n",
    "repository_name = 'pinocchio'\n",
    "commits_file = 'commits_pinocchio_latest.json'\n",
    "branch_name = \"master\"\n",
    "\n",
    "core_prefixes = [\"bindings\", \"models\", \"include\", \"unittest\", \"src\"]\n",
    "major_contributors = [\"Justin Carpentier\" , \"Gabriele Buondonno\" , \"Joseph Mirabel\"  , \"Rohan Budhiraja\" , \"Nicolas Mansard\", \"Florian Valenza\", \"Guilhem Saurel\", \"Florent Lamiraux\", \"Joris Vaillant\" , \"Wilson Jallet\" ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e133c-638c-46af-a610-376f70bd6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "### hpp-fcl\n",
    "\n",
    "organisation = 'humanoid-path-planner'\n",
    "repository_name = 'hpp-fcl'\n",
    "commits_file = 'commits_hpp-fcl_latest.json'\n",
    "branch_name = \"master\"\n",
    "\n",
    "core_prefixes = [\"python\", \"src\", \"include\", \"test\"]\n",
    "major_contributors = [\"Florent Lamiraux\", \"Joseph Mirabel\", \"Justin Carpentier\", \"Louis Montaut\", \"Guilhem Saurel\", \"Jia Pan\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aefd34-4695-4814-b793-cb5f12fe38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### eigenpy\n",
    "\n",
    "organisation = 'stack-of-tasks'\n",
    "repository_name = 'eigenpy'\n",
    "commits_file = 'commits_eigenpy_latest.json'\n",
    "branch_name = \"master\"\n",
    "\n",
    "core_prefixes = [\"bindings\", \"models\", \"include\", \"unittest\", \"src\"]\n",
    "major_contributors = [\"Justin Carpentier\" ,\"Joris Vaillant\" , \"Wilson Jallet\", \"Guilhem Saurel\", \"Nicolas Mansard\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6963e8-6610-4056-8b24-a6fef03cf9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### proxsuite\n",
    "\n",
    "organisation = 'Simple-Robotics'\n",
    "repository_name = 'proxsuite'\n",
    "commits_file = 'commits_proxsuite_latest.json'\n",
    "branch_name = \"main\"\n",
    "\n",
    "core_prefixes = [\"test\", \"include\", \"bindings\"]\n",
    "major_contributors = [\"Sarah El-Kazdadi\", \"Antoine Bambade\", \"Justin Carpentier\", \"Fabian Schramm\", \"Stéphane Caron\", \"Wolfgang Merkt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58325eb-e47b-438e-95b4-bf3615c03d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### proxsuite-nlp\n",
    "\n",
    "organisation = 'Simple-Robotics'\n",
    "repository_name = 'proxsuite-nlp'\n",
    "commits_file = 'commits_proxsuite_nlp_latest.json'\n",
    "branch_name = \"main\"\n",
    "\n",
    "core_prefixes = [\"src\", \"scripts\", \"tests\", \"bindings\", \"include\"]\n",
    "major_contributors = [\"Wilson Jallet\" ,\"Joris Vaillant\" , \"Alessandro Assirell\", \"Fabian Schramm\", \"Sarah El-Kazdadi\", \"Justin Carpentier\", \"Nicolas Mansard\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd71917-6373-42d7-b67a-2f78a74eed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "### aligator\n",
    "\n",
    "organisation = 'Simple-Robotics'\n",
    "repository_name = 'aligator'\n",
    "commits_file = 'commits_aligator_latest.json'\n",
    "branch_name = \"main\"\n",
    "\n",
    "core_prefixes = [\"src\", \"scripts\", \"tests\", \"bindings\", \"include\"]\n",
    "major_contributors = [\"Wilson Jallet\" ,\"Quentin Le Lidec\" , \"Joris Vaillant\", \"Fabian Schramm\", \"Stéphane Caron\", \"Guilhem Saurel\", \"Justin Carpentier\", \"Nicolas Mansard\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfdf7b2-1039-4001-8be6-7df599d5990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### cosypose\n",
    "\n",
    "organisation = 'Simple-Robotics'\n",
    "repository_name = 'cosypose'\n",
    "commits_file = 'commits_cosypose_latest.json'\n",
    "branch_name = \"master\"\n",
    "\n",
    "core_prefixes  = [\"cosypose\", \"notebooks\"]\n",
    "major_contributors  = [\"Yann Labbe\", \"Stephen Tyree\", \"Mederic Fourmy\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8ebad-2ef1-4739-a27e-c18c8c3d73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### pycppad\n",
    "\n",
    "organisation = 'Simple-Robotics'\n",
    "repository_name = 'pycppad'\n",
    "commits_file = 'commits_pycppad_latest.json'\n",
    "branch_name = \"master\"\n",
    "\n",
    "core_prefixes = [\"python\", \"include\", \"src\"]\n",
    "major_contributors = [\"Rohan Budhiraja\" ,\"Justin Carpentier\" , \"Guilhem Saurel\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c4597-6c8f-4888-8ca2-44c881918216",
   "metadata": {},
   "source": [
    "## Download commits from Github\n",
    "\n",
    "WARNING : may take a lot of time. Only perform when a new version needs to be processed.\n",
    "\n",
    "Notes\n",
    "- When checking for contributors, always use the author, not the commiter. The author is the person who originally wrote the code. The committer, on the other hand, is assumed to be the person who committed the code on behalf of the original author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01877da5-e0ef-4de7-8ee2-8a4f444c104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_repo_commits(token, org, repo_name, output):\n",
    "    # Replace with your personal access token\n",
    "    g = Github(token)\n",
    "\n",
    "    print (repo_name)\n",
    "    print (org)\n",
    "    print (output)\n",
    "\n",
    "    # Replace with your organization and repository name\n",
    "    org = g.get_organization(org)\n",
    "    repo = org.get_repo(repo_name)\n",
    "\n",
    "    # Get all branches\n",
    "    branches = repo.get_branches()\n",
    "\n",
    "    all_commits = []\n",
    "\n",
    "    # For each branch, retrieve and print its commits\n",
    "    for branch in branches:\n",
    "        print(f\"Commits for branch: {branch.name}\")\n",
    "        branch_commits = repo.get_commits(sha=branch.name)\n",
    "        for commit in branch_commits:\n",
    "            #commit[\"BRANCH\"] = branch\n",
    "            commit.raw_data[\"BRANCH\"] = branch.name\n",
    "            print(commit.sha)\n",
    "            print (commit.raw_data)\n",
    "            print (type(commit.raw_data))\n",
    "            all_commits.append(commit)\n",
    "            break\n",
    "\n",
    "    #all_commits_dict = []\n",
    "\n",
    "    #for commit in all_commits:\n",
    "    #    all_commits_dict.append(commit.raw_data)\n",
    "\n",
    "    #with open(output, 'w') as outfile:\n",
    "    #    json.dump(all_commits_dict, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a803c499-d725-47d1-82ca-d059b62a8161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the config of the project\n",
    "print (organisation)\n",
    "print(repository_name)\n",
    "print(commits_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6ff5c-1cbe-4b6b-8815-23add976d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to start the download (may take a lot of time)\n",
    "# commits_filename =  \"./data/\" +commits_file\n",
    "# download_repo_commits(access_token, organisation, repository_name, commits_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8196b2-17ee-4b96-8ee1-9898b8926121",
   "metadata": {},
   "source": [
    "## Load authors renaming info from CSV file\n",
    "\n",
    "load a csv with two columns. \n",
    "- First one is \"name\",\n",
    "- Second one is \"rename\".\n",
    "\n",
    "Used to rename authors of commits that use different names on different setups.\n",
    "This also allows to have proper first/last name for the authors in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc711b-6d41-478c-90c1-7ec23e97265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergers_df = pd.read_csv('./data/renaming_authors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1e2816-2e26-420e-a52e-b09a58a73d99",
   "metadata": {},
   "source": [
    "## Load contributors affiliation from CSV file\n",
    "\n",
    "Load separate file with known affiliations for different accounts in order to do proper attribution (i.e., person name, login and email, with date range and employer's name).\n",
    "\n",
    "When a person is not in this file, or the date of the commit for a person is outside the date range of a known affiliation, the default UNKNOWN attribution is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edaa79e-d875-435f-80be-957be57fd450",
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliation_df = pd.read_csv('./data/account_affiliation.csv')\n",
    "\n",
    "# Display content for debut/info\n",
    "# print(affiliation_df.columns.tolist())\n",
    "# print(affiliation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba272a5-facf-42d0-837e-d22d759b4c70",
   "metadata": {},
   "source": [
    "## Load commits dictionnary from json file\n",
    "\n",
    "Load the commits dictionnary from the local file created after the Github download.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914db90-9668-4660-9958-fe4e71f8b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_repo_commits(filename):\n",
    "    commits_list = []\n",
    "    commits_dict = {}\n",
    "\n",
    "    print(\"Load file : \" + filename)\n",
    "    with open(filename, 'r') as json_file:\n",
    "        # Load the JSON file into a Python dictionary\n",
    "        commits_list = json.load(json_file)\n",
    "\n",
    "    for commit in commits_list:\n",
    "        renames = mergers_df[(mergers_df['name'] == commit['commit']['author']['name'])]\n",
    "        rename = renames['rename'].iloc[0] if not renames.empty else commit['commit']['author']['name']\n",
    "        commit['commit']['author']['name'] = rename\n",
    "\n",
    "    for commit in commits_list:\n",
    "        commitid = commit[\"sha\"]\n",
    "        commits_dict[commitid] = commit\n",
    "\n",
    "    return commits_list, commits_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324c210-d9e9-48f4-a83d-3ed9bab2d4fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the commits file (downloaded from Github) and convert to dataframe\n",
    "print (organisation)\n",
    "print(repository_name)\n",
    "\n",
    "commits_filename =  \"./data/\" +commits_file\n",
    "print (commits_filename)\n",
    "\n",
    "all_commits_dict, commit_dict = init_repo_commits(commits_filename)\n",
    "\n",
    "# print the number of rows/commits (including merge)\n",
    "print(len(all_commits_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e3d4be-d656-4882-b941-35951ec9644a",
   "metadata": {},
   "source": [
    "## Process the dataframe to expand nested information\n",
    "\n",
    "- First expand some nested information\n",
    "- Then drop useless columns\n",
    "- And concert/rename some others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a181b8-7515-4b70-8ec1-c6b29e625a98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalize JSON data\n",
    "\n",
    "all_commits_dict_df = pd.DataFrame(all_commits_dict)\n",
    "\n",
    "# expand author (to retrieve login, date, ...)\n",
    "df_normalized = pd.json_normalize(all_commits_dict_df['author'])\n",
    "df_normalized = df_normalized.add_prefix('author.')\n",
    "all_commits_dict_df = pd.concat([all_commits_dict_df, df_normalized], axis=1)\n",
    "\n",
    "# expand commit\n",
    "df_normalized = pd.json_normalize(all_commits_dict_df['commit'])\n",
    "df_normalized = df_normalized.add_prefix('commit.')\n",
    "all_commits_dict_df = pd.concat([all_commits_dict_df, df_normalized], axis=1)\n",
    "\n",
    "# expand stats to get LoC add/del/total\n",
    "df_normalized = pd.json_normalize(all_commits_dict_df['stats'])\n",
    "df_normalized = df_normalized.add_prefix('stats.')\n",
    "all_commits_dict_df = pd.concat([all_commits_dict_df, df_normalized], axis=1)\n",
    "\n",
    "# display all the new column names\n",
    "# print(all_commits_dict_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b8ee4-d2c8-4ced-86b9-c9fe6e144a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug purposes\n",
    "# all_commits_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd14d8-d0a3-428a-acf8-310bd7d949da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns not providing any meaningful information\n",
    "\n",
    "columns_to_delete = [\n",
    "    'node_id', \n",
    "    'commit', 'stats',\n",
    "    'author', 'committer', 'message', 'comment_count',\n",
    "    'url', 'html_url', 'comments_url',\n",
    "    'committer.name', 'committer.email', 'committer.date',\n",
    "    'tree.sha', 'tree.url',\n",
    "    'verification.verified', 'verification.reason', 'verification.signature', 'verification.payload'\n",
    "]\n",
    "\n",
    "for col in columns_to_delete:\n",
    "    try:\n",
    "        all_commits_dict_df = all_commits_dict_df.drop([col], axis=1)\n",
    "    except (KeyError):\n",
    "        print (\"Non existent column : \" + col)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b9fa6-b737-4c29-b33b-be3a79b36af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert and rename columns\n",
    "\n",
    "# author.date as the contribution's DATE\n",
    "# all_commits_dict_df['author.date'] = pd.to_datetime(all_commits_dict_df['author.date'])\n",
    "all_commits_dict_df['DATE'] = pd.to_datetime(all_commits_dict_df['commit.author.date']).dt.date\n",
    "\n",
    "# author.login as LOGIN to use for the contribution\n",
    "all_commits_dict_df.rename(columns={\"author.login\": \"LOGIN\"}, inplace=True)\n",
    "all_commits_dict_df.rename(columns={\"EMAIL\" : \"commit.author.email\"}, inplace=True)\n",
    "all_commits_dict_df.rename(columns={\"NAME\" : \"commit.author.name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a82a9-781f-4f49-aa38-dd76493677c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most recent commit, to add info (sha/date) in the final report\n",
    "most_recent_commit = all_commits_dict_df.loc[all_commits_dict_df['commit.author.date'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ed435-14a5-4cc0-85cf-c735b184b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_authors = all_commits_dict_df['LOGIN'].unique()\n",
    "all_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f9905-f5cf-44df-a308-f5967651842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_commits_dict_df['IS_MERGE'] = all_commits_dict_df['parents'].apply(lambda x: True if len(x) > 1 else False)\n",
    "\n",
    "true_count_merge = all_commits_dict_df['IS_MERGE'].sum()\n",
    "print(f\"Numer of merge requests {true_count_merge}\")\n",
    "print(f\"Number of commits and merge {len(all_commits_dict_df)}\")\n",
    "\n",
    "NUMBER_COMMITS_WITH_MERGE = len(all_commits_dict_df)\n",
    "NUMBER_MERGE = true_count_merge\n",
    "NUMBER_COMMITS = NUMBER_COMMITS_WITH_MERGE-NUMBER_MERGE\n",
    "\n",
    "NUMBER_CONTRIBUTORS = len(all_authors)\n",
    "NUMBER_MAIN_CONTRIBUTORS = len(major_contributors)\n",
    "\n",
    "print(f\"Numer of contributors {NUMBER_CONTRIBUTORS}\")\n",
    "print(f\"Number of main contributors {NUMBER_MAIN_CONTRIBUTORS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1bbd5-2614-4761-b690-af9c599ad1be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# known affiliations for this repository\n",
    "filtered_affiliation_df = affiliation_df[affiliation_df['LOGIN'].isin(all_authors)]\n",
    "filtered_affiliation_df\n",
    "\n",
    "# display the table for the know affiliations in the current contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e91b3-3e5a-4a67-bdc6-49053829020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use table generated directly instead\n",
    "\n",
    "# export df to image\n",
    "# image_filename = \"./output/\"+ repository_name +\"_contributors_affiliation.png\"\n",
    "# image_filenames['TABLE_CONTRIBUTORS_AFFILIATIONS'] = image_filename\n",
    "# dfi.export(filtered_affiliation_df.style.hide(axis='index'), image_filename, dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7bcace-c7aa-4310-bafe-623180cff247",
   "metadata": {},
   "source": [
    "## Add core contribution flag to the contributions' dataframe\n",
    "\n",
    "Use lambda to add extra column with TRUE value if one of the files modified by this commit is with the core folders of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf4f24-df0f-493f-a700-863cec215c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Core folders for this project : {core_prefixes}\")\n",
    "\n",
    "all_commits_dict_df['has_core_contrib'] = all_commits_dict_df['files'].apply(lambda x: any(obj['filename'].startswith(tuple(core_prefixes)) for obj in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6ddcc-2058-445f-bcfb-e55c378383f1",
   "metadata": {},
   "source": [
    "## Add affiliation to the contributions' dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d88f86e-a8a8-4ed5-ac78-df01c3375594",
   "metadata": {},
   "source": [
    "Now merge the affiliation dataframe into the commits dataframe, using the author LOGIN (left merge).\n",
    "\n",
    "Then filter rows where the date is outside the affiliation's date range and fill any missing value with UNKNOWN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a4182-170d-4063-8d1b-9ca0ed9bca90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_commits_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d53de-9d97-462c-b25b-01aea10bbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(all_commits_dict_df))\n",
    "\n",
    "## First attempt by merging on affiliation and then filtering per date\n",
    "## but issue when known affiliation is only for a short time. Side-effect is that\n",
    "## commits outside this affiiation will be filtered (and not converted to UNKNOWN)\n",
    "##\n",
    "## # create the merged_df dataframe adding the AFFILIATION as well as START/END columns\n",
    "## all_commits_dict_df = all_commits_dict_df.merge(affiliation_df, on=\"LOGIN\", how='left')\n",
    "## # filter rows where the date is within the range\n",
    "## all_commits_dict_df = all_commits_dict_df.loc[(all_commits_dict_df['commit.author.date'] >= all_commits_dict_df['START']) | (all_commits_dict_df['START'].isna())]\n",
    "## all_commits_dict_df = all_commits_dict_df.loc[(all_commits_dict_df['commit.author.date'] <= all_commits_dict_df['END']) | (all_commits_dict_df['END'].isna())]\n",
    "## # fill missing values with 'UNKNOWN' for affiliation\n",
    "## all_commits_dict_df2['AFFILIATION'] = all_commits_dict_df2['AFFILIATION'].fillna('UNKNOWN')\n",
    "\n",
    "def get_affiliation(given_login, given_date):\n",
    "    given_date = pd.to_datetime(given_date)\n",
    "    # Filter rows that match the given name and date falls within the start and end date range\n",
    "    affiliation_rows = affiliation_df[(affiliation_df['LOGIN'] == given_login) & (affiliation_df['START'] <= given_date) & (affiliation_df['END'] >= given_date)]    \n",
    "    # Get the affiliation value for the first matching row\n",
    "    affiliation_value = affiliation_rows['AFFILIATION'].iloc[0] if not affiliation_rows.empty else 'UNKNOWN'\n",
    "    return affiliation_value\n",
    "\n",
    "def get_name(given_login):\n",
    "    rows = affiliation_df[(affiliation_df['LOGIN'] == given_login)]    \n",
    "    # Get the affiliation value for the first matching row\n",
    "    value = rows['NAME'].iloc[0] if not rows.empty else None\n",
    "    return value\n",
    "\n",
    "def get_email(given_login):\n",
    "    rows = affiliation_df[(affiliation_df['LOGIN'] == given_login)]    \n",
    "    # Get the affiliation value for the first matching row\n",
    "    value = rows['EMAIL'].iloc[0] if not rows.empty else None\n",
    "    return value\n",
    "    \n",
    "affiliation_df['START'] = pd.to_datetime(affiliation_df['START'])\n",
    "affiliation_df['END'] = pd.to_datetime(affiliation_df['END'])\n",
    "\n",
    "all_commits_dict_df['AFFILIATION'] = all_commits_dict_df.apply(lambda x: get_affiliation(x['LOGIN'], x['DATE']), axis=1)\n",
    "\n",
    "all_commits_dict_df['NAME'] = all_commits_dict_df['LOGIN'].apply(get_name)\n",
    "all_commits_dict_df['EMAIL'] = all_commits_dict_df['LOGIN'].apply(get_email)\n",
    "\n",
    "#print (len(all_commits_dict_df))\n",
    "\n",
    "#print(\"list of all the contributors\")\n",
    "#print(all_commits_dict_df['LOGIN'].unique())\n",
    "#print(\"list of all the affiliations\")\n",
    "#print(all_commits_dict_df['AFFILIATION'].unique())\n",
    "\n",
    "#print (len(all_commits_dict_df))\n",
    "\n",
    "# copy from other columns for name and email\n",
    "all_commits_dict_df['NAME'] = all_commits_dict_df['NAME'].fillna(all_commits_dict_df['commit.author.name'])\n",
    "all_commits_dict_df['EMAIL'] = all_commits_dict_df['EMAIL'].fillna(all_commits_dict_df['commit.author.email'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b71d6-6112-4e13-8bfb-017ec6372028",
   "metadata": {},
   "source": [
    "## Generate tables and charts with contribution information per affiliation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e01a0-adc3-4fd4-b7a2-15047bc51143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count the LoC ops for each user and affiliation\n",
    "sum_df = all_commits_dict_df.loc[~all_commits_dict_df['IS_MERGE']].groupby(['LOGIN', 'AFFILIATION','NAME']).agg(\n",
    "    loc_total=('stats.total', 'sum'),\n",
    "    loc_deletions=('stats.deletions', 'sum'),\n",
    "    loc_additions=('stats.additions', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# count the number of commits for each user and affiliation\n",
    "grouped_counts = all_commits_dict_df.loc[~all_commits_dict_df['IS_MERGE']].groupby(['LOGIN', 'AFFILIATION','NAME']).size().reset_index(name='count')\n",
    "\n",
    "# merge the count column in the previous table\n",
    "sum_df.insert(2, 'count', grouped_counts['count'])\n",
    "\n",
    "# group by affiliation only\n",
    "affiliation_sum_df = sum_df.groupby(['AFFILIATION']).agg(\n",
    "    count=('count', 'sum'),\n",
    "    loc_total=('loc_total', 'sum'),\n",
    "    loc_deletions=('loc_deletions', 'sum'),\n",
    "    loc_additions=('loc_additions', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# group by name only\n",
    "name_sum_df = sum_df.groupby(['NAME']).agg(\n",
    "    count=('count', 'sum'),\n",
    "    loc_total=('loc_total', 'sum'),\n",
    "    loc_deletions=('loc_deletions', 'sum'),\n",
    "    loc_additions=('loc_additions', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Now rename columns before display\n",
    "sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_total\": \"LoC total\",\n",
    "                       \"loc_deletions\": \"LoC del\",\n",
    "                       \"loc_additions\": \"LoC add\"\n",
    "                      }, inplace=True)\n",
    "affiliation_sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_total\": \"LoC total\",\n",
    "                       \"loc_deletions\": \"LoC del\",\n",
    "                       \"loc_additions\": \"LoC add\"\n",
    "                      }, inplace=True)\n",
    "name_sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_total\": \"LoC total\",\n",
    "                       \"loc_deletions\": \"LoC del\",\n",
    "                       \"loc_additions\": \"LoC add\"\n",
    "                      }, inplace=True)\n",
    "\n",
    "## WARNING : do not sort these dataframes as it may create merge/index issues later \n",
    "affiliation_sum_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da739e8c-1c74-4622-93ab-4a345afbbd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_commits_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab427d-8026-4477-a2d6-0427b6f4b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export df to image (no core stats - check below for another fig)\n",
    "image_filename = \"./output/\"+ repository_name +\"_stats_affiliation.png\"\n",
    "image_filenames['TABLE_AFFILIATIONS_STATS_FULL'] = image_filename\n",
    "\n",
    "dfi.export(affiliation_sum_df.style.hide(axis='index'), image_filename, dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030e3b6-40fe-480a-a8e8-b30ecc90fc94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# name_sum_df = name_sum_df.sort_values(by='Commits', ascending=False)\n",
    "filtered_name_sum_df = name_sum_df[name_sum_df['NAME'].isin(major_contributors)]\n",
    "filtered_name_sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bec431-fb53-498b-ac0a-f2b54534ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the table above as png  (no core stats)\n",
    "image_filename = \"./output/\"+ repository_name +\"_main_contributors_stats_full.png\"\n",
    "image_filenames[\"TABLE_CONTRIBUTORS_STATS_FULL\"] = image_filename\n",
    "\n",
    "dfi.export(filtered_name_sum_df.style.hide(axis='index'), image_filename, dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1684d29a-7e5d-4dca-8971-2f24f225667b",
   "metadata": {},
   "source": [
    "## Generate tables and charts with contribution information per affiliation for core contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc94776c-2309-4733-a050-a8381e456a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_df =  all_commits_dict_df[all_commits_dict_df['has_core_contrib'] == True].loc[~all_commits_dict_df['IS_MERGE']]\n",
    "\n",
    "# count the LoC ops for each user and affiliation\n",
    "core_sum_df = core_df.groupby(['LOGIN', 'AFFILIATION','NAME']).agg(\n",
    "    loc_total=('stats.total', 'sum'),\n",
    "    loc_deletions=('stats.deletions', 'sum'),\n",
    "    loc_additions=('stats.additions', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# count the number of commits for each user and affiliation\n",
    "core_grouped_counts = core_df.groupby(['LOGIN', 'AFFILIATION','NAME']).size().reset_index(name='count')\n",
    "\n",
    "# merge the count column in the previous table\n",
    "core_sum_df.insert(2, 'count', core_grouped_counts['count'])\n",
    "\n",
    "# group by affiliation only\n",
    "affiliation_core_sum_df = core_sum_df.groupby(['AFFILIATION']).agg(\n",
    "    count=('count', 'sum'),\n",
    "    loc_total=('loc_total', 'sum'),\n",
    "    loc_deletions=('loc_deletions', 'sum'),\n",
    "    loc_additions=('loc_additions', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# group by name only\n",
    "name_core_sum_df = core_sum_df.groupby(['NAME']).agg(\n",
    "    count=('count', 'sum'),\n",
    "    loc_total=('loc_total', 'sum'),\n",
    "    loc_deletions=('loc_deletions', 'sum'),\n",
    "    loc_additions=('loc_additions', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Now rename columns\n",
    "core_sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_total\": \"LoC total\",\n",
    "                       \"loc_deletions\": \"LoC del\",\n",
    "                       \"loc_additions\": \"LoC add\"\n",
    "                      }, inplace=True)\n",
    "affiliation_core_sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_total\": \"LoC total\",\n",
    "                       \"loc_deletions\": \"LoC del\",\n",
    "                       \"loc_additions\": \"LoC add\"\n",
    "                      }, inplace=True)\n",
    "name_core_sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_total\": \"LoC total\",\n",
    "                       \"loc_deletions\": \"LoC del\",\n",
    "                       \"loc_additions\": \"LoC add\"\n",
    "                      }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a780ccc-9746-490e-929e-725ce0d9aead",
   "metadata": {},
   "source": [
    "## Latest code origin\n",
    "\n",
    "We now analyze the current state of the repository (Pinocchio v2.7.0) and determine the origin (commit) for all the lines of code. If some code was deleted, or rewritten, the initial contribution (commit/author) is therefore not considered in these statistics.\n",
    "\n",
    "We use `git blame` to get the last commit for each line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a025a20-c7d3-46b7-95cd-2e4866ef26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_local_path = \"./\" + repository_name\n",
    "\n",
    "# Initialize the repository object\n",
    "repo = Repo(repository_local_path)\n",
    "\n",
    "# lists of commit IDs with LoC still in latest version (core and all folders)\n",
    "final_commit_list = []\n",
    "final_core_commit_list = []\n",
    "\n",
    "final_commits_loc_dict = {}\n",
    "final_core_commit_loc_list = {}\n",
    "\n",
    "# list of authors names with commits still in latest version (core and all folders)\n",
    "authors_contrib_dict = {}\n",
    "authors_core_contrib_dict = {}\n",
    "\n",
    "# list of authors names with LoC still in latest version (core and all folders)\n",
    "authors_loc_contrib_dict = {}\n",
    "authors_loc_core_contrib_dict = {}\n",
    "\n",
    "commit = repo.head.commit # Get the current commit\n",
    "tree = commit.tree # Get the tree of the commit\n",
    "for blob in tree.traverse():\n",
    "    if blob.type == 'blob': # Check if the object is a file\n",
    "        file = blob.path\n",
    "\n",
    "        # Iterate through all files in the repository\n",
    "        # Get the blame output for the file\n",
    "        blame_output = repo.git.blame(\"--line-porcelain\", file).split(\"\\n\")\n",
    "        previous_line = \"\"\n",
    "\n",
    "        author = \"\"\n",
    "        \n",
    "        # Process the blame output to extract author information\n",
    "        for line in blame_output:\n",
    "            # iterate until we find an author line, get the commit id from the previous line\n",
    "            if line.startswith(\"author \"):\n",
    "                commitid = previous_line.split()[0]\n",
    "                author = line[len(\"author \"):]\n",
    "\n",
    "                # merge same author with different names\n",
    "                renames = mergers_df[(mergers_df['name'] == author)]\n",
    "                author = renames['rename'].iloc[0] if not renames.empty else author\n",
    "        \n",
    "                # first time we find a line for this commit, initialize LoC related info\n",
    "                if commitid not in final_commit_list:\n",
    "                    # new commit, remember it\n",
    "                    final_commit_list.append(commitid)\n",
    "                    # also add +1 new commit for this author\n",
    "                    authors_contrib_dict.setdefault(author, 0)\n",
    "                    authors_contrib_dict[author] += 1\n",
    "\n",
    "                if commitid not in final_commits_loc_dict:\n",
    "                    # new commit, remember it\n",
    "                    final_commits_loc_dict.setdefault(commitid, 0)\n",
    "                final_commits_loc_dict[commitid] += 1\n",
    "                \n",
    "                # known or not commit, add +1 line for author\n",
    "                authors_loc_contrib_dict.setdefault(author, 0)\n",
    "                authors_loc_contrib_dict[author] += 1\n",
    "\n",
    "                # is file par of the core folders ?\n",
    "                if (file.startswith(tuple(core_prefixes))):\n",
    "                    if commitid not in final_core_commit_list:\n",
    "                        # new commit, remember it\n",
    "                        final_core_commit_list.append(commitid)\n",
    "                        # also add +1 new commit for this author\n",
    "                        authors_core_contrib_dict.setdefault(author, 0)\n",
    "                        authors_core_contrib_dict[author] += 1\n",
    "\n",
    "                    # known or not commit, add +1 core line for author\n",
    "                    authors_loc_core_contrib_dict.setdefault(author, 0)\n",
    "                    authors_loc_core_contrib_dict[author] += 1\n",
    "\n",
    "            previous_line = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b6c55-eed8-443c-b990-95caf447dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_repo_commit_sha = repo.head.object.hexsha\n",
    "commit_row = all_commits_dict_df.loc[all_commits_dict_df['sha'] == local_repo_commit_sha].iloc[0]\n",
    "local_repo_commit_date = commit_row['DATE']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de85994-5764-4cf5-9961-d807e5045a22",
   "metadata": {},
   "source": [
    "## Display charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5ff50-99d3-44d3-9d29-595f6dc1c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.transforms import Bbox\n",
    "\n",
    "def display_piechart(title, values, labels, image_filename):\n",
    "\n",
    "    # Creating the pie chart\n",
    "    plt.pie(values, labels=labels, autopct='%1.1f%%')\n",
    "    plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.savefig(image_filename)\n",
    "    plt.show()\n",
    "\n",
    "def display_barchart_compare(title, xlabels, xlabel, ylabel, values_series1, label1, image_filename):\n",
    "    x = np.arange(len(xlabels))\n",
    "    fig_width = 5 + int(len(xlabel)/3)\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, 5))\n",
    "    width = 0.70 # Width of the bars\n",
    "\n",
    "    # Plot the first series\n",
    "    bars1 = plt.bar(x - width/2, values_series1, width, label=label1, color='b')\n",
    "\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.xticks(x, xlabels)\n",
    "    plt.legend()\n",
    "\n",
    "    # save the fig before show !\n",
    "    plt.savefig(image_filename, bbox_inches=Bbox([[0,-2],fig.get_size_inches()]))\n",
    "    plt.show()\n",
    "    \n",
    "def display_2barcharts_compare(title, xlabels, xlabel, ylabel, values_series1, values_series2, label1, label2, image_filename):\n",
    "    x = np.arange(len(xlabels))\n",
    "    fig_width = 5 + int(len(xlabel)/3)\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, 5))\n",
    "    width = 0.35 # Width of the bars\n",
    "\n",
    "    # Plot the first series\n",
    "    bars1 = plt.bar(x - width/2, values_series1, width, label=label1, color='b')\n",
    "\n",
    "    # Plot the second series\n",
    "    bars2 = plt.bar(x + width/2, values_series2, width, label=label2, color='g')\n",
    "\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.xticks(x, xlabels)\n",
    "    plt.legend()\n",
    "\n",
    "    # save the fig before show !\n",
    "    plt.savefig(image_filename, bbox_inches=Bbox([[0,-2],fig.get_size_inches()]))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_3barcharts_compare(title, \n",
    "                               xlabels, xlabel, ylabel, \n",
    "                               values_series1, values_series2, values_series3, \n",
    "                               label1, label2, label3, \n",
    "                               image_filename):\n",
    "    \n",
    "    x = np.arange(len(xlabels))\n",
    "    fig_width = 5 + int(len(xlabel)/3)\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, 5))\n",
    "    width = 0.25 # Width of the bars\n",
    "\n",
    "    # Plot the first series\n",
    "    bars1 = plt.bar(x - width, values_series1, width, label=label1, color='b')\n",
    "    bars2 = plt.bar(x, values_series2, width, label=label2, color='r')\n",
    "    bars3 = plt.bar(x + width, values_series3, width, label=label3, color='b')\n",
    "\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.xticks(x, xlabels)\n",
    "    plt.legend()\n",
    "\n",
    "    # save the fig before show !\n",
    "    plt.savefig(image_filename, bbox_inches=Bbox([[0,-2],fig.get_size_inches()]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865bb023-a43e-4f5d-ac7e-c4bc97e38f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scalable_2barcharts_compare(title, \n",
    "                               xlabels, xlabel, ylabel, \n",
    "                               values_series1, values_series2,\n",
    "                               label1, label2,\n",
    "                               image_filename):\n",
    "\n",
    "    fig_width = 5 + int(len(xlabels)/3)\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, 5))\n",
    "\n",
    "    barWidth = 0.25\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    x = np.arange(len(categories))\n",
    "    \n",
    "    # Width of the bars\n",
    "    width = 0.35\n",
    "\n",
    "    # Plot the series\n",
    "    plt.bar(x - width/2, values_series1, width, label=label1, color='b')\n",
    "    plt.bar(x + width/2, values_series2, width, label=label2, color='g')\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=45)  \n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.xticks(x, xlabels)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(image_filename)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0bdc27-0a3f-428c-9cf6-f7be2d643a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_vertical_barchart(title, \n",
    "                               xlabels, xlabel, ylabel, \n",
    "                               values_series1,\n",
    "                               label1,\n",
    "                               image_filename):\n",
    "\n",
    "    # now a vertical barchart\n",
    "    fig_height = 5 + int(len(xlabels)/5)\n",
    "    fig, ax = plt.subplots(figsize=(5, fig_height))\n",
    "    \n",
    "    # Creating the bar chart\n",
    "    bars = plt.barh(xlabels, values_series1, color='green')\n",
    "    \n",
    "    # Adding value labels on the bars\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2,\n",
    "                 f'{bar.get_width()}', va='center', fontsize=6)\n",
    "    \n",
    "    # Adding labels and title\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel, fontsize=20)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.savefig(image_filename)\n",
    "\n",
    "    # Showing the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af77da-7729-4c04-9ee1-a223baf7d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export merging df to image\n",
    "image_filename = \"./output/\"+ repository_name +\"_mergers.png\"\n",
    "image_filenames['ACCOUNT_MERGING_TABLE'] = image_filename\n",
    "\n",
    "dfi.export(mergers_df.style.hide(axis='index'), image_filename, dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a40b87-4d00-43e7-81ab-2bf4a145e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows based on list values\n",
    "## create mask\n",
    "# mask = name_sum_df['NAME'].isin(major_contributors)\n",
    "## apply mask\n",
    "# filtered_df = name_sum_df[mask]\n",
    "# filtered_core_df = name_core_sum_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd2c1f-ad53-4508-92bb-2f1e1d6fefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare commits per affiliation (all and core)\n",
    "\n",
    "result = affiliation_sum_df.merge(affiliation_core_sum_df, \n",
    "                      on=['AFFILIATION'], \n",
    "                      suffixes=['','_core'],\n",
    "                      how='left')\n",
    "  \n",
    "# Fill missing values with zero\n",
    "result.fillna(0, inplace=True)\n",
    "\n",
    "# Reset the index if needed\n",
    "result.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "xlabels = result[\"AFFILIATION\"].tolist()\n",
    "title = \"Commits per affiliation (full project)\"\n",
    "xlabel = \"Affiliations\"\n",
    "ylabel = \"Commits\"\n",
    "values_series1 = result[\"Commits\"].tolist()\n",
    "values_series2 = result[\"Commits_core\"].tolist()\n",
    "label1 = \"All commits\"\n",
    "label2 = \"Core commits\"\n",
    "image_filename = \"./output/\"+ repository_name +\"_commits_per_affiliation.png\"\n",
    "image_filenames['CHART_COMMITS_AFFILIATION'] = image_filename\n",
    "\n",
    "display_2barcharts_compare(title, xlabels, \n",
    "                          xlabel, ylabel, \n",
    "                          values_series1, values_series2, \n",
    "                          label1, label2, \n",
    "                          image_filename)\n",
    "\n",
    "# now the same data as a pie chart\n",
    "\n",
    "title = \"Commits per affiliation (full project)\"\n",
    "values = affiliation_sum_df['Commits'].values\n",
    "labels = affiliation_sum_df['AFFILIATION'].values\n",
    "\n",
    "image_filename = \"./output/\"+ repository_name +\"_pie_commits_per_affiliation.png\"\n",
    "image_filenames['PIE_COMMITS_AFFILIATION'] = image_filename\n",
    "\n",
    "display_piechart(title, values, labels, image_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bad09a-4619-44d8-abe2-1f674fbd395b",
   "metadata": {},
   "source": [
    "Display the percentage of contributions per affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a936fc-ba2b-4b34-a124-53925aa5b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LoC per affiliation (all then core)\n",
    "\n",
    "result = affiliation_sum_df.merge(affiliation_core_sum_df, \n",
    "                      on=['AFFILIATION'], \n",
    "                      suffixes=['','_core'],\n",
    "                      how='left')\n",
    "  \n",
    "# Fill missing values with zero\n",
    "result.fillna(0, inplace=True)\n",
    "\n",
    "# Reset the index if needed\n",
    "result.reset_index(inplace=True)\n",
    "\n",
    "xlabels = result[\"AFFILIATION\"].tolist()\n",
    "title = \"LoC per affiliation (full project)\"\n",
    "xlabel = \"Affiliations\"\n",
    "ylabel = \"LoC\"\n",
    "values_series1 = result[\"LoC total\"].tolist()\n",
    "values_series2 = result[\"LoC del\"].tolist()\n",
    "values_series3 = result[\"LoC add\"].tolist()\n",
    "label1 = \"All LoC\"\n",
    "label2 = \"LoC del\"\n",
    "label3 = \"LoC add\"\n",
    "image_filename = \"./output/\"+ repository_name +\"_loc_per_affiliation.png\"\n",
    "image_filenames['CHART_LOC_AFFILIATION'] = image_filename\n",
    "\n",
    "display_3barcharts_compare(title, xlabels, \n",
    "                          xlabel, ylabel, \n",
    "                          values_series1, values_series2, values_series3,\n",
    "                          label1, label2, label3,\n",
    "                          image_filename)\n",
    "\n",
    "# now the same data as a pie chart\n",
    "\n",
    "title = \"LoC per affiliation (full project)\"\n",
    "values = result['LoC total'].values\n",
    "labels = result[\"AFFILIATION\"].values\n",
    "\n",
    "image_filename = \"./output/\"+ repository_name +\"_pie_loc_per_affiliation.png\"\n",
    "image_filenames['PIE_LOC_AFFILIATION'] = image_filename\n",
    "\n",
    "display_piechart(title, values, labels, image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f24f88-13e8-4017-b1b3-eb893902e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de67e9d-790e-4210-a2c2-bc6be9c82586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the table above as image for the report (all and core files)\n",
    "result.drop('index', axis=1, inplace=True)\n",
    "image_filename = \"./output/\"+ repository_name +\"_table_affiliations_stats_full_with_core.png\"\n",
    "image_filenames['TABLE_AFFILIATIONS_STATS_FULL_WITH_CORE'] = image_filename\n",
    "\n",
    "dfi.export(result.style.hide(axis='index'), image_filename, dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45162647-bc94-4038-b29d-b6d78b9a9d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LoC per affiliation (all)\n",
    "\n",
    "# Filter rows based on list values\n",
    "filtered_df = name_sum_df[name_sum_df['NAME'].isin(major_contributors)]\n",
    "filtered_core_df = name_core_sum_df[name_core_sum_df['NAME'].isin(major_contributors)]\n",
    "\n",
    "# filtered_core_df = filtered_core_df.sort_values('NAME')\n",
    "\n",
    "filtered_others_df = name_sum_df[~name_sum_df['NAME'].isin(major_contributors)]\n",
    "filtered_others_sum = filtered_others_df.sum()\n",
    "filtered_others_sum['NAME'] = 'Others'\n",
    "\n",
    "filtered_others_core_df = name_core_sum_df[~name_core_sum_df['NAME'].isin(major_contributors)]\n",
    "filtered_others_core_sum = filtered_others_core_df.sum()\n",
    "filtered_others_core_sum['NAME'] = 'Others'\n",
    "\n",
    "filtered_df = pd.concat([filtered_df, pd.DataFrame([filtered_others_sum])], ignore_index=True)\n",
    "filtered_core_df = pd.concat([filtered_core_df, pd.DataFrame([filtered_others_core_sum])], ignore_index=True)\n",
    "\n",
    "\n",
    "result = filtered_df.merge(filtered_core_df, \n",
    "                      on=['NAME'], \n",
    "                      suffixes=['','_core'],\n",
    "                      how='left')\n",
    "\n",
    "# Fill missing values with zero\n",
    "result.fillna(0, inplace=True)\n",
    "\n",
    "# Reset the index if needed\n",
    "result.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8909d3-9abd-416e-a381-f095a63ba41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display main contributors LoC and Commits for the full project\n",
    "\n",
    "# barcharts for the LoC\n",
    "xlabels = result[\"NAME\"].tolist()\n",
    "title = \"Main contributors LoC (full project)\"\n",
    "xlabel = \"Contributors\"\n",
    "ylabel = \"LoC\"\n",
    "values_series1 = result[\"LoC total\"].tolist()\n",
    "values_series2 = result[\"LoC del\"].tolist()\n",
    "values_series3 = result[\"LoC add\"].tolist()\n",
    "label1 = \"All LoC\"\n",
    "label2 = \"LoC del\"\n",
    "label3 = \"LoC add\"\n",
    "image_filename = \"./output/\"+ repository_name +\"_loc_per_contributors.png\"\n",
    "image_filenames['CHART_MAIN_CONTRIBUTORS_LOC'] = image_filename\n",
    "\n",
    "display_3barcharts_compare(title, xlabels, \n",
    "                          xlabel, ylabel, \n",
    "                          values_series1, values_series2, values_series3,\n",
    "                          label1, label2, label3,\n",
    "                          image_filename)\n",
    "\n",
    "# now the barcharts for the commits\n",
    "xlabels = result[\"NAME\"].tolist()\n",
    "title = \"Main contributors commits (full project)\"\n",
    "xlabel = \"Contributors\"\n",
    "ylabel = \"Commits\"\n",
    "values_series1 = result[\"Commits\"].tolist()\n",
    "values_series2 = result[\"Commits_core\"].tolist()\n",
    "label1 = \"All commits\"\n",
    "label2 = \"Core commits\"\n",
    "image_filename = \"./output/\"+ repository_name +\"_commits_per_main_.png\"\n",
    "image_filenames['CHART_MAIN_CONTRIBUTORS_COMMITS'] = image_filename\n",
    "\n",
    "display_2barcharts_compare(title, xlabels, \n",
    "                          xlabel, ylabel, \n",
    "                          values_series1, values_series2, \n",
    "                          label1, label2, \n",
    "                          image_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6da0dc-d9aa-4f79-b36b-230f7efca258",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c60a4a-1352-4d8d-bd7c-8b2dffcc9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the same data as a pie chart\n",
    "\n",
    "# LoC\n",
    "title = \"Main contributors total LoC total (full project)\"\n",
    "values = result['LoC total'].values\n",
    "labels = result[\"NAME\"].values\n",
    "\n",
    "image_filename = \"./output/\"+ repository_name +\"_pie_loc_per_contributors_full.png\"\n",
    "image_filenames['PIE_FULL_LOC_MAIN_CONTRIBUTORS'] = image_filename\n",
    "\n",
    "display_piechart(title, values, labels, image_filename)\n",
    "\n",
    "# Commits\n",
    "title = \"Main contributors commits (full project)\"\n",
    "values = result['Commits'].values\n",
    "labels = result['NAME'].values\n",
    "\n",
    "image_filename = \"./output/\"+ repository_name +\"_pie_commits_per_contributors_full.png\"\n",
    "image_filenames['PIE_FULL_COMMITS_MAIN_CONTRIBUTORS'] = image_filename\n",
    "\n",
    "display_piechart(title, values, labels, image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d64a2-322c-4c89-8666-78f6d6889eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c1dc2-e1ed-4aae-83cf-b76a56b80d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display contributors' LoC in the lastest version of the project\n",
    "\n",
    "categories = []\n",
    "values_series1 = []\n",
    "values_series2 = []\n",
    "\n",
    "for contributor in authors_contrib_dict:\n",
    "    try:\n",
    "        val1 = authors_loc_contrib_dict[contributor]\n",
    "        val2 = authors_loc_core_contrib_dict[contributor]\n",
    "        \n",
    "        values_series1.append(val1)\n",
    "        values_series2.append(val2)\n",
    "        categories.append(contributor)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "image_filename = \"./output/\" + repository_name + \"_all_contributors_latest_code_loc.png\"\n",
    "image_filenames['CHART_LATEST_LOC_ALL_CONTRIBUTORS'] = image_filename\n",
    "\n",
    "display_scalable_2barcharts_compare('Project contributors LoC (latest code)',\n",
    "                                    categories, 'Contributors', 'Commits',\n",
    "                                    values_series1, values_series2,\n",
    "                                    'All files', 'Core files',\n",
    "                                    image_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1242f0-e561-48c7-a328-596bdae0c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display commits for latest code\n",
    "\n",
    "sorted_dict = dict(sorted(authors_core_contrib_dict.items(), key=lambda item: item[1], reverse=False))\n",
    "\n",
    "# Extracting keys and values from the dictionary\n",
    "keys = list(sorted_dict.keys())\n",
    "values = list(sorted_dict.values())\n",
    "\n",
    "image_filename = \"./output/\" + repository_name + \"_vert_chart_commits_core_files.png\"\n",
    "image_filenames['CHART_LATEST_CORE_COMMITS_ALL_CONTRIBUTORS'] = image_filename\n",
    "\n",
    "display_vertical_barchart('Contributors commits for core files (latest code)', \n",
    "                               keys, 'Commits', 'Authors', \n",
    "                               values,\n",
    "                               label1,\n",
    "                               image_filename)\n",
    "\n",
    "\n",
    "sorted_dict = dict(sorted(authors_contrib_dict.items(), key=lambda item: item[1], reverse=False))\n",
    "\n",
    "# Extracting keys and values from the dictionary\n",
    "keys = list(sorted_dict.keys())\n",
    "values = list(sorted_dict.values())\n",
    "\n",
    "image_filename = \"./output/\" + repository_name + \"_vert_chart_commits_all_files.png\"\n",
    "image_filenames['CHART_LATEST_COMMITS_ALL_CONTRIBUTORS'] = image_filename\n",
    "\n",
    "display_vertical_barchart('Contributors commits for all files (latest code)', \n",
    "                               keys, 'Commits', 'Authors', \n",
    "                               values,\n",
    "                               label1,\n",
    "                               image_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bae4cf-358f-4946-ad1e-1d9413cb9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now display the timeline for commits\n",
    "\n",
    "final_core_commits_timeline = {}\n",
    "final_commits_timeline = {}\n",
    "commits_timeline = {}\n",
    "core_commits_timeline = {}\n",
    "categories = []\n",
    "\n",
    "for year in range(2010,2025):\n",
    "    for month in range(1,13):\n",
    "        kwd=f\"{year}-{month:02d}\"\n",
    "        final_core_commits_timeline.setdefault(kwd, 0)\n",
    "        final_commits_timeline.setdefault(kwd, 0)\n",
    "        commits_timeline.setdefault(kwd, 0)\n",
    "        core_commits_timeline.setdefault(kwd, 0)\n",
    "        categories.append(kwd)\n",
    "\n",
    "core_commit_list = list(filter(\n",
    "    lambda commit: any(file.get('filename', '').startswith(tuple(core_prefixes)) for file in commit.get('files', [])),\n",
    "    all_commits_dict\n",
    "))\n",
    "\n",
    "missing_commits=0\n",
    "\n",
    "for commitid in final_core_commit_list:\n",
    "    try:\n",
    "        commit = commit_dict[commitid]\n",
    "        commit_date = datetime.strptime(commit['commit']['author']['date'], '%Y-%m-%dT%H:%M:%SZ').date()\n",
    "        key=f\"{commit_date.year}-{commit_date.month:02d}\"\n",
    "        final_core_commits_timeline[key] += 1\n",
    "    except KeyError:\n",
    "        missing_commits += 1\n",
    "        pass\n",
    "\n",
    "print(f\"missing commits {missing_commits}\")\n",
    "missing_commits=0\n",
    "\n",
    "for commitid in final_commit_list:\n",
    "    try:\n",
    "        commit = commit_dict[commitid]\n",
    "        commit_date = datetime.strptime(commit['commit']['author']['date'], '%Y-%m-%dT%H:%M:%SZ').date()\n",
    "        key=f\"{commit_date.year}-{commit_date.month:02d}\"\n",
    "        final_commits_timeline[key] += 1\n",
    "    except KeyError:\n",
    "        #print (\"Error 2 with commit ID : \" + commitid)\n",
    "        #key=f\"{commit_date.year}-{commit_date.month:02d}\"\n",
    "        #print(key)\n",
    "        missing_commits += 1\n",
    "        pass\n",
    "\n",
    "print(f\"missing commits {missing_commits}\")\n",
    "missing_commits=0\n",
    "\n",
    "sorted_final_core_commits_timeline = OrderedDict(sorted(final_core_commits_timeline.items()))\n",
    "sorted_final_commits_timeline = OrderedDict(sorted(final_commits_timeline.items()))\n",
    "\n",
    "for commit in all_commits_dict:\n",
    "    try:\n",
    "        commit_date = datetime.strptime(commit['commit']['author']['date'], '%Y-%m-%dT%H:%M:%SZ').date()\n",
    "        key=f\"{commit_date.year}-{commit_date.month:02d}\"\n",
    "        commits_timeline[key] += 1\n",
    "    except KeyError:\n",
    "        missing_commits += 1\n",
    "        pass\n",
    "        \n",
    "sorted_commits_timeline = OrderedDict(sorted(commits_timeline.items()))\n",
    "\n",
    "print(f\"missing commits {missing_commits}\")\n",
    "missing_commits=0\n",
    "\n",
    "for commit in core_commit_list:\n",
    "    try:\n",
    "        commit_date = datetime.strptime(commit['commit']['author']['date'], '%Y-%m-%dT%H:%M:%SZ').date()\n",
    "        key=f\"{commit_date.year}-{commit_date.month:02d}\"\n",
    "        core_commits_timeline[key] += 1\n",
    "    except KeyError:\n",
    "        missing_commits += 1\n",
    "        pass\n",
    "        \n",
    "# sorted_core_commits_timeline = OrderedDict(sorted(core_commits_timeline.items()))\n",
    "# quarterly_sum = sorted_core_commits_timeline_df.groupby(sorted_core_commits_timeline_df['date'].dt.to_period('Q')).sum()\n",
    "# print(f\"missing commits {missing_commits}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image_filename = \"./output/\" + repository_name + \"_timeline_latest_code_commits.png\"\n",
    "image_filenames['TIMELINE_LATEST_COMMITS_ALL_CORE'] = image_filename\n",
    "display_scalable_2barcharts_compare('Project timeline for commits for latest version (all and core files)',\n",
    "                                    categories, 'Timeline', 'Commits',\n",
    "                                    sorted_final_commits_timeline.values(), sorted_final_core_commits_timeline.values(),\n",
    "                                    'All files', 'Core files',\n",
    "                                    image_filename)\n",
    "\n",
    "\n",
    "image_filename = \"./output/\" + repository_name + \"_timeline_all_latest_commits.png\"\n",
    "image_filenames['TIMELINE_COMMITS_ALL_LATEST'] = image_filename\n",
    "display_scalable_2barcharts_compare('Project timeline for commits (all and latest version)',\n",
    "                                    categories, 'Timeline', 'Commits',\n",
    "                                    sorted_commits_timeline.values(), sorted_final_commits_timeline.values(),\n",
    "                                    'All project', 'Latest version',\n",
    "                                    image_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e2ef1-61c8-456f-8a52-575cee0248e5",
   "metadata": {},
   "source": [
    "# Latest code images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a97e45-5b75-4121-a5a3-c91c022dfee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# final_commit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe3972f-f4e6-40bd-8833-9bf0b303e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = all_commits_dict_df['sha'].isin(final_commit_list)\n",
    "latest_all_commits_dict_df = all_commits_dict_df[mask]\n",
    "latest_all_commits_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14871819-97c7-4688-b3a3-c07c2c429077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create dataframe from the commit-LoC dictionnary just created \n",
    "df = pd.DataFrame.from_dict(final_commits_loc_dict, orient='index', columns=['loc_latest'])\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'sha'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02449568-5750-44bd-bb89-ec7a9e582fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe that merge the loc_latest column in the table with the dataframe of the commits for the latest code\n",
    "latest_merged_df = pd.merge(latest_all_commits_dict_df, df[['sha', 'loc_latest']], on='sha', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b8686-b779-44dd-ba9f-e755611087aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create merged dataframes to count the LoC ops for each user and affiliation\n",
    "latest_sum_df = latest_merged_df.loc[~latest_merged_df['IS_MERGE']].groupby(['LOGIN', 'AFFILIATION','NAME']).agg(\n",
    "    loc_latest=('loc_latest', 'sum'),\n",
    ").reset_index()\n",
    "\n",
    "# count the number of commits for each user and affiliation\n",
    "latest_grouped_counts = latest_merged_df.loc[~latest_merged_df['IS_MERGE']].groupby(['LOGIN', 'AFFILIATION', 'NAME']).size().reset_index(name='count')\n",
    "\n",
    "# merge the count column in the previous table\n",
    "latest_sum_df.insert(2, 'count', latest_grouped_counts['count'])\n",
    "\n",
    "# group by affiliation only\n",
    "latest_affiliation_sum_df = latest_sum_df.groupby(['AFFILIATION']).agg(\n",
    "    count=('count', 'sum'),\n",
    "    loc_latest=('loc_latest', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# group by name only\n",
    "latest_name_sum_df = latest_sum_df.groupby(['NAME']).agg(\n",
    "    count=('count', 'sum'),\n",
    "    loc_latest=('loc_latest', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Now rename columns before display (all the columns are about latest code)\n",
    "latest_sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_latest\": \"LoC\"\n",
    "                      }, inplace=True)\n",
    "latest_affiliation_sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_latest\": \"LoC\"\n",
    "                      }, inplace=True)\n",
    "latest_name_sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_latest\": \"LoC\"\n",
    "                      }, inplace=True)\n",
    "\n",
    "##\n",
    "## Now compute the same stats for core commits only\n",
    "##\n",
    "\n",
    "core_latest_merged_df = latest_merged_df[latest_merged_df['has_core_contrib'] == True].loc[~latest_merged_df['IS_MERGE']]\n",
    "\n",
    "# count the number of commits for each user and affiliation\n",
    "core_latest_sum_df = core_latest_merged_df.loc[~core_latest_merged_df['IS_MERGE']].groupby(['LOGIN', 'AFFILIATION','NAME']).agg(\n",
    "    loc_latest=('loc_latest', 'sum'),\n",
    ").reset_index()\n",
    "\n",
    "# count the number of commits for each user and affiliation\n",
    "core_latest_grouped_counts = core_latest_merged_df.loc[~core_latest_merged_df['IS_MERGE']].groupby(['LOGIN', 'AFFILIATION', 'NAME']).size().reset_index(name='count')\n",
    "\n",
    "# merge the count column in the previous table\n",
    "core_latest_sum_df.insert(2, 'count', core_latest_grouped_counts['count'])\n",
    "\n",
    "# group by affiliation only\n",
    "core_latest_affiliation_sum_df = core_latest_sum_df.groupby(['AFFILIATION']).agg(\n",
    "    count=('count', 'sum'),\n",
    "    loc_latest=('loc_latest', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# group by name only\n",
    "core_latest_name_sum_df = core_latest_sum_df.groupby(['NAME']).agg(\n",
    "    count=('count', 'sum'),\n",
    "    loc_latest=('loc_latest', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Now rename columns before display (all the columns are about latest code)\n",
    "core_latest_sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_latest\": \"LoC\"\n",
    "                      }, inplace=True)\n",
    "core_latest_affiliation_sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_latest\": \"LoC\"\n",
    "                      }, inplace=True)\n",
    "core_latest_name_sum_df.rename(columns={\"count\": \"Commits\",\n",
    "                       \"loc_latest\": \"LoC\"\n",
    "                      }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e9116-348f-471c-894b-edfaa8e2a94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare LoC per affiliation (latest code)\n",
    "\n",
    "# Filter rows based on list values\n",
    "filtered_df = latest_name_sum_df[latest_name_sum_df['NAME'].isin(major_contributors)]\n",
    "filtered_core_df = core_latest_name_sum_df[core_latest_name_sum_df['NAME'].isin(major_contributors)]\n",
    "\n",
    "filtered_others_df = latest_name_sum_df[~latest_name_sum_df['NAME'].isin(major_contributors)]\n",
    "filtered_others_sum = filtered_others_df.sum()\n",
    "filtered_others_sum['NAME'] = 'Others'\n",
    "\n",
    "filtered_others_core_df = core_latest_name_sum_df[~core_latest_name_sum_df['NAME'].isin(major_contributors)]\n",
    "filtered_others_core_sum = filtered_others_core_df.sum()\n",
    "filtered_others_core_sum['NAME'] = 'Others'\n",
    "\n",
    "filtered_df = pd.concat([filtered_df, pd.DataFrame([filtered_others_sum])], ignore_index=True)\n",
    "filtered_core_df = pd.concat([filtered_core_df, pd.DataFrame([filtered_others_core_sum])], ignore_index=True)\n",
    "\n",
    "result = filtered_df.merge(filtered_core_df, \n",
    "                      on=['NAME'], \n",
    "                      suffixes=['','_core'],\n",
    "                      how='left')\n",
    "\n",
    "# Fill missing values with zero\n",
    "result.fillna(0, inplace=True)\n",
    "\n",
    "# Reset the index if needed\n",
    "result.reset_index(inplace=True)\n",
    "\n",
    "xlabels = result[\"NAME\"].tolist()\n",
    "title = \"Main contributors LoC (latest code)\"\n",
    "xlabel = \"Contributors\"\n",
    "ylabel = \"LoC\"\n",
    "values_series1 = result[\"LoC\"].tolist()\n",
    "values_series2 = result[\"LoC_core\"].tolist()\n",
    "label1 = \"All LoC\"\n",
    "label2 = \"Core LoC\"\n",
    "image_filename = \"./output/\"+ repository_name +\"_loc_per_contributors_latest.png\"\n",
    "image_filenames['CHART_LATEST_LOC_MAIN_CONTRIBUTORS'] = image_filename\n",
    "\n",
    "display_2barcharts_compare(title, xlabels, \n",
    "                          xlabel, ylabel, \n",
    "                          values_series1, values_series2,\n",
    "                          label1, label2,\n",
    "                          image_filename)\n",
    "\n",
    "xlabels = result[\"NAME\"].tolist()\n",
    "title = \"Main contributors commits (latest code)\"\n",
    "xlabel = \"Contributors\"\n",
    "ylabel = \"Commits\"\n",
    "values_series1 = result[\"Commits\"].tolist()\n",
    "values_series2 = result[\"Commits_core\"].tolist()\n",
    "label1 = \"All commits\"\n",
    "label2 = \"Core commits\"\n",
    "image_filename = \"./output/\"+ repository_name +\"_commits_per_main_.png\"\n",
    "image_filenames['CHART_LATEST_COMMITS_MAIN_CONTRIBUTORS'] = image_filename\n",
    "\n",
    "display_2barcharts_compare(title, xlabels, \n",
    "                          xlabel, ylabel, \n",
    "                          values_series1, values_series2, \n",
    "                          label1, label2, \n",
    "                          image_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46fcd0-5ba7-4a1e-8efd-b135284d52d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the same data as a pie chart\n",
    "\n",
    "title = \"Main contributors LoC (latest code)\"\n",
    "values = result['LoC'].values\n",
    "labels = result[\"NAME\"].values\n",
    "\n",
    "image_filename = \"./output/\"+ repository_name +\"_pie_loc_per_contributors_latest.png\"\n",
    "image_filenames['PIE_LATEST_LOC_MAIN_CONTRIBUTORS'] = image_filename\n",
    "\n",
    "display_piechart(title, values, labels, image_filename)\n",
    "\n",
    "# now the same data as a pie chart\n",
    "\n",
    "title = \"Main contributors commits (latest code)\"\n",
    "values = result['Commits'].values\n",
    "labels = result['NAME'].values\n",
    "\n",
    "image_filename = \"./output/\"+ repository_name +\"_pie_commits_per_contributors_latest.png\"\n",
    "image_filenames['PIE_LATEST_COMMITS_MAIN_CONTRIBUTORS'] = image_filename\n",
    "\n",
    "display_piechart(title, values, labels, image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc26e4-40a8-49e4-bc58-8d25814d9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d356d6-1483-49d0-b163-80c9feb0bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the table above as image for the report\n",
    "result.drop('index', axis=1, inplace=True)\n",
    "result.rename(columns={\"Commits_core\": \"Commits Core\",\n",
    "                       \"LoC_core\": \"LoC Core\"\n",
    "                      }, inplace=True)\n",
    "image_filename = \"./output/\"+ repository_name +\"_table_contributors_stats_latest.png\"\n",
    "image_filenames['TABLE_CONTRIBUTORS_STATS_LATEST'] = image_filename\n",
    "\n",
    "dfi.export(result.style.hide(axis='index'), image_filename, dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b0d7c-b8bd-432b-b357-2258d3cb833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle case when less affiliations in core than in all\n",
    "\n",
    "# Identify unique AFFILIATION values in both DataFrames\n",
    "unique_aff_all = set(latest_affiliation_sum_df['AFFILIATION'])\n",
    "unique_aff_core = set(core_latest_affiliation_sum_df['AFFILIATION'])\n",
    "# Find AFFILIATION values that are in all but not in core\n",
    "missing_aff = unique_aff_all - unique_aff_core\n",
    "# Create new rows with missing AFFILIATION values in core, setting all other column values to zero\n",
    "new_rows = pd.DataFrame({'AFFILIATION': list(missing_aff)})\n",
    "for col in core_latest_affiliation_sum_df.columns:\n",
    "    if col != 'AFFILIATION':\n",
    "        new_rows[col] = 0\n",
    "# Concatenate the original df2 with the newly created rows\n",
    "core_latest_affiliation_sum_df = pd.concat([core_latest_affiliation_sum_df, new_rows], ignore_index=True)\n",
    "# Reset the index if needed\n",
    "core_latest_affiliation_sum_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# sort so that same order\n",
    "latest_affiliation_sum_df = latest_affiliation_sum_df.sort_values('AFFILIATION')\n",
    "core_latest_affiliation_sum_df = core_latest_affiliation_sum_df.sort_values('AFFILIATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfb242b-27b0-4b14-91c6-4e18c2b389f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_latest_affiliation_sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c60998-a138-4d9d-942d-5a2a99d02edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_affiliation_sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ff740-5736-4dd5-8b9b-2ff6157fc52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare commits per affiliation (all and core)\n",
    "result = latest_affiliation_sum_df.merge(core_latest_affiliation_sum_df, \n",
    "                      on=['AFFILIATION'], \n",
    "                      suffixes=['','_core'],\n",
    "                      how='left')\n",
    "  \n",
    "# Fill missing values with zero\n",
    "result.fillna(0, inplace=True)\n",
    "\n",
    "# Reset the index if needed\n",
    "result.reset_index(inplace=True)\n",
    "\n",
    "xlabels = result[\"AFFILIATION\"].tolist()\n",
    "title = \"Latest-code Commits per affiliation\"\n",
    "xlabel = \"Affiliations\"\n",
    "ylabel = \"Commits\"\n",
    "values_series1 = latest_affiliation_sum_df[\"Commits\"].tolist()\n",
    "values_series2 = core_latest_affiliation_sum_df[\"Commits\"].tolist()\n",
    "label1 = \"All commits\"\n",
    "label2 = \"Core commits\"\n",
    "\n",
    "image_filename = \"./output/\"+ repository_name +\"_latest_commits_per_affiliation.png\"\n",
    "image_filenames['CHART_LATEST_COMMITS_AFFILIATION'] = image_filename\n",
    "\n",
    "display_2barcharts_compare(title, xlabels, \n",
    "                          xlabel, ylabel, \n",
    "                          values_series1, values_series2, \n",
    "                          label1, label2, \n",
    "                          image_filename)\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83cd043-b0ea-4082-aa32-b093b2048463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare LoC per affiliation (all then core)\n",
    "\n",
    "#result = affiliation_sum_df.merge(latest_affiliation_sum_df, \n",
    "#                      on=['AFFILIATION'], \n",
    "#                      suffixes=['','_core'],\n",
    "#                      how='left')\n",
    "  \n",
    "# Fill missing values with zero\n",
    "#result.fillna(0, inplace=True)\n",
    "\n",
    "# Reset the index if needed\n",
    "#result.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "xlabels = result[\"AFFILIATION\"].tolist()\n",
    "title = \"Latest-code LoC per affiliation\"\n",
    "xlabel = \"Affiliations\"\n",
    "ylabel = \"LoC\"\n",
    "values_series1 = latest_affiliation_sum_df[\"LoC\"].tolist()\n",
    "values_series2 = core_latest_affiliation_sum_df[\"LoC\"].tolist()\n",
    "label1 = \"All commits\"\n",
    "label2 = \"Core commits\"\n",
    "image_filename = \"./output/\"+ repository_name +\"_latest_loc_per_affiliation.png\"\n",
    "image_filenames['CHART_LATEST_LOC_AFFILIATION'] = image_filename\n",
    "\n",
    "display_2barcharts_compare(title, xlabels, \n",
    "                          xlabel, ylabel, \n",
    "                          values_series1, values_series2, \n",
    "                          label1, label2, \n",
    "                          image_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da58a0-7a6c-48d1-b99a-837b3fbe5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f6583-3d0e-4ff5-bc87-555c1a4fac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.drop('index', axis=1, inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4492b8b8-1530-470b-bbc0-b46eb01a2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filename = \"./output/\"+ repository_name +\"_table_latest_affiliations_info.png\"\n",
    "image_filenames['TABLE_LATEST_INFO_AFFILIATION'] = image_filename\n",
    "\n",
    "dfi.export(result.style.hide(axis='index'), image_filename, dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a13cca8-44a5-45c6-86ea-8498044c1faf",
   "metadata": {},
   "source": [
    "## Generate template file for contributors affiliations for this project\n",
    "\n",
    "Generate a file with the timeframe (start,end) for the contributions (commits date) to this project. This can be used to generate the affiliations' file to be used for employers attribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8774b-01e2-4a9f-a8b6-ba5683562785",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_contrib_affiliation_filename = \"contributors_affiliation_\" + repository_name + \".csv\"\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "for commit in all_commits_dict:\n",
    "    key = commit['commit']['author']['name']\n",
    "    item = data_dict.get(key)\n",
    "    if item is None:\n",
    "        item = [\n",
    "            commit['commit']['author']['name'],\n",
    "            commit['commit']['author']['email'],\n",
    "            \"\",\n",
    "            \"\",\n",
    "            0,\n",
    "            commit['commit']['author']['date'],\n",
    "            commit['commit']['author']['date'],\n",
    "            commit['stats']['total'],\n",
    "            commit['stats']['additions'],\n",
    "            commit['stats']['deletions'],\n",
    "            0,\n",
    "            0,\n",
    "            0\n",
    "        ]\n",
    "        try:\n",
    "            item[2] = commit['author']['login']\n",
    "            item[3] = commit['author']['id']\n",
    "        except (KeyError, TypeError):\n",
    "            pass\n",
    "\n",
    "    item[4] = item[4] + 1\n",
    "    item[7] = item[7] + commit['stats']['total']\n",
    "    item[8] = item[8] + commit['stats']['additions']\n",
    "    item[9] = item[9] + commit['stats']['deletions']\n",
    "    if commit['commit']['author']['date'] <= item[5]:\n",
    "        item[5] = commit['commit']['author']['date']\n",
    "    if commit['commit']['author']['date'] >= item[6]:\n",
    "        item[6] = commit['commit']['author']['date']\n",
    "\n",
    "    for file in commit.get('files', []):\n",
    "        if file.get('filename', '').startswith(tuple(core_prefixes)):\n",
    "            item[10] = item[10] + file.get('changes')\n",
    "            item[11] = item[11] + file.get('additions')\n",
    "            item[12] = item[12] + file.get('deletions')\n",
    "\n",
    "    data_dict[key] = item\n",
    "\n",
    "\n",
    "title = [\"NAME\",\n",
    "         \"EMAIL\",\n",
    "         \"LOGIN\",\n",
    "         \"GHID\",\n",
    "         \"COMMITS\",\n",
    "         \"START\",\n",
    "         \"END\",\n",
    "         \"LOC TOTAL\",\n",
    "         \"LOC ADD\",\n",
    "         \"LOC DEL\",\n",
    "         \"CORE LOC TOTAL\",\n",
    "         \"CORE LOC ADD\",\n",
    "         \"CORE LOC DEL\",\n",
    "        ]\n",
    "\n",
    "csv_items = list(data_dict.values())\n",
    "\n",
    "# convert date (no time)\n",
    "for csv_item in csv_items:\n",
    "    csv_item[5] = datetime.strptime(csv_item[5], \"%Y-%m-%dT%H:%M:%SZ\").date();\n",
    "    csv_item[6] = datetime.strptime(csv_item[6], \"%Y-%m-%dT%H:%M:%SZ\").date();\n",
    "   \n",
    "with open(csv_contrib_affiliation_filename, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(title)\n",
    "    writer.writerows(csv_items)\n",
    "\n",
    "print(\"Generated the affiliation template file \" + csv_contrib_affiliation_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5765e05-3035-4e2a-a317-790587e17a38",
   "metadata": {},
   "source": [
    "## Generating Markdown Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bfcb0e-33d9-4354-99b2-f99c8f46b576",
   "metadata": {},
   "source": [
    "First some generic function to create the markdown tables to include in the final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f4831-50ab-4b7d-8713-833a7ea5442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMajorContributorsTable(contributors):\n",
    "    str = \"| Main contributors |\\n\" + \"| ----------------- |\\n\"\n",
    "\n",
    "    for contrib in contributors:\n",
    "        str += \"|\" + contrib + \"|\\n\"\n",
    "\n",
    "    return str\n",
    "\n",
    "def getMergersTable(mergers):\n",
    "    str = \"| Contributor | Renammed as |\\n\" + \"| -------- | --------- |\\n\"\n",
    "\n",
    "    for index, row in mergers_df.iterrows():\n",
    "        str += \"|\" + row['name'] + \"|\" + row['rename'] + \"|\\n\"\n",
    "\n",
    "    return str\n",
    "\n",
    "def getCoreFoldersTable(folders):\n",
    "    str = \"| Folders |\\n\" + \"| ----------------- |\\n\"\n",
    "\n",
    "    for folder in folders:\n",
    "        str += \"|\" + folder + \"|\\n\"\n",
    "\n",
    "    return str\n",
    "\n",
    "def getAffiliationsTable(affiliations):\n",
    "    str = \"| Name | Affiliation | Start | End |\\n\" + \"| -------- | --------- | --------- | --------- |\\n\"\n",
    "\n",
    "    for index, row in affiliations.iterrows():\n",
    "        str += \"|\" + row['NAME'] + \"|\" + row['AFFILIATION'] + \"|\" + row['START'] + \"|\" + row['END'] + \"|\\n\"\n",
    "\n",
    "    return str\n",
    "\n",
    "\n",
    "def format_contrib_row(row):\n",
    "    return f\"| {row['NAME']} | {row['Commits']} | {row['LoC add']} | {row['% Commit']} | {row['% LoC add']} | {row['Main contrib']} | {row['Latest LoC']} | {row['% Latest LoC']} |\\n\"\n",
    "\n",
    "\n",
    "def getContributorsTable(contributors):\n",
    "    str = \"| Contributor | Commits | LoC add | % Commit | % LoC add | Main contrib | Latest LoC | % Latest LoC |\\n\"  \n",
    "    str += \"| ------------------------------------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |\\n\"\n",
    "\n",
    "    for index, row in contributors.iterrows():\n",
    "        str += format_contrib_row(row)\n",
    "        \n",
    "    return str\n",
    "\n",
    "\n",
    "def getAuthorshipTable(main_contribs):\n",
    "    str = \"| Contributor | Percentage | Comments | \\n\"  \n",
    "    str += \"| ---------------------- | ----------- | ------------------------------------- |\\n\"\n",
    "\n",
    "    for name in main_contribs:\n",
    "        str += \"|\" + name + \"| | |\\n\"\n",
    "        str += \"| | | |\\n\"\n",
    "        \n",
    "    return str\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61051a49-f725-4dc6-b9ee-5cc436aa5333",
   "metadata": {},
   "source": [
    "Now read the template report, replace the template text with the relevant data and save as a new report. PDF generation should be done from any Markdown app (Python libraries are currently too limited).\n",
    "\n",
    "This also allows to add new hindsight on the data/charts being added in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a3b77f-644d-46bd-ae79-94adebf05e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedata = None\n",
    "\n",
    "# Read in the file\n",
    "with open('./data/report_template.md', 'r') as file:\n",
    "  filedata = file.read()\n",
    "\n",
    "today = str(date.today())\n",
    "project_url = \"https://github.com/\" + organisation + \"/\" + repository_name\n",
    "\n",
    "# Replace configuration strings\n",
    "filedata = filedata.replace('PROJECT_NAME', repository_name)\n",
    "filedata = filedata.replace('ORGANIZATION', organisation)\n",
    "filedata = filedata.replace('PROJECT_URL', project_url)\n",
    "filedata = filedata.replace('REPORT_DATE', today)\n",
    "\n",
    "filedata = filedata.replace('GHSTATS_URL', notebook_url)\n",
    "\n",
    "# General info\n",
    "filedata = filedata.replace('NUMBER_COMMITS_WITH_MERGE', str(NUMBER_COMMITS_WITH_MERGE))\n",
    "filedata = filedata.replace('NUMBER_MERGE', str(NUMBER_MERGE))\n",
    "filedata = filedata.replace('NUMBER_COMMITS', str(NUMBER_COMMITS))\n",
    "filedata = filedata.replace('NUMBER_CONTRIBUTORS', str(NUMBER_CONTRIBUTORS))\n",
    "filedata = filedata.replace('NUMBER_MAIN_CONTRIBUTORS', str(NUMBER_MAIN_CONTRIBUTORS))\n",
    "\n",
    "filedata = filedata.replace('LATEST_COMMIT_SHA', str(most_recent_commit['sha']))\n",
    "filedata = filedata.replace('LATEST_COMMIT_DATE', str(most_recent_commit['DATE']))\n",
    "\n",
    "filedata = filedata.replace('LOCAL_REPO_COMMIT_SHA', str(local_repo_commit_sha))\n",
    "filedata = filedata.replace('LOCAL_REPO_COMMIT_DATE', str(local_repo_commit_date))\n",
    "\n",
    "# Contributors accounts (main, merge)\n",
    "filedata = filedata.replace('MAIN_CONTRIBUTORS_TABLE', getMajorContributorsTable(major_contributors) )\n",
    "filedata = filedata.replace('ACCOUNT_MERGING_TABLE', getMergersTable(mergers_df) )\n",
    "# use the filtered DF with only people that contributed to this project\n",
    "filedata = filedata.replace('ACCOUNT_AFFILIATION_TABLE', getAffiliationsTable(filtered_affiliation_df) )\n",
    "\n",
    "# Core folders table\n",
    "filedata = filedata.replace('CORE_FOLDERS_TABLE', getCoreFoldersTable(core_prefixes) )\n",
    "\n",
    "# Full project\n",
    "\n",
    "## Main contributors\n",
    "\n",
    "filedata = filedata.replace('CHART_MAIN_CONTRIBUTORS_COMMITS', image_filenames['CHART_MAIN_CONTRIBUTORS_COMMITS'])\n",
    "filedata = filedata.replace('CHART_MAIN_CONTRIBUTORS_LOC', image_filenames['CHART_MAIN_CONTRIBUTORS_LOC'])\n",
    "\n",
    "filedata = filedata.replace('PIE_FULL_COMMITS_MAIN_CONTRIBUTORS', image_filenames['PIE_FULL_COMMITS_MAIN_CONTRIBUTORS'])\n",
    "filedata = filedata.replace('PIE_FULL_LOC_MAIN_CONTRIBUTORS', image_filenames['PIE_FULL_LOC_MAIN_CONTRIBUTORS'])\n",
    "\n",
    "filedata = filedata.replace('TABLE_CONTRIBUTORS_STATS_FULL', image_filenames['TABLE_CONTRIBUTORS_STATS_FULL'])\n",
    "\n",
    "## Affiliation\n",
    "\n",
    "filedata = filedata.replace('CHART_COMMITS_AFFILIATION', image_filenames['CHART_COMMITS_AFFILIATION'])\n",
    "filedata = filedata.replace('CHART_LOC_AFFILIATION', image_filenames['CHART_LOC_AFFILIATION'])\n",
    "\n",
    "filedata = filedata.replace('PIE_COMMITS_AFFILIATION', image_filenames['PIE_COMMITS_AFFILIATION'])\n",
    "filedata = filedata.replace('PIE_LOC_AFFILIATION', image_filenames['PIE_LOC_AFFILIATION'])\n",
    "\n",
    "# table with commits/LoC per affiliation on all/core files, whole project\n",
    "# filedata = filedata.replace('TABLE_AFFILIATIONS_STATS_FULL', image_filenames['TABLE_AFFILIATIONS_STATS_FULL'])\n",
    "filedata = filedata.replace('TABLE_AFFILIATIONS_STATS_FULL_WITH_CORE', image_filenames['TABLE_AFFILIATIONS_STATS_FULL_WITH_CORE'])\n",
    "\n",
    "\n",
    "# Latest code\n",
    "\n",
    "## affiliations\n",
    "\n",
    "filedata = filedata.replace('CHART_LATEST_COMMITS_AFFILIATION', image_filenames['CHART_LATEST_COMMITS_AFFILIATION'])\n",
    "filedata = filedata.replace('CHART_LATEST_LOC_AFFILIATION', image_filenames['CHART_LATEST_LOC_AFFILIATION'])\n",
    "\n",
    "filedata = filedata.replace('TABLE_LATEST_INFO_AFFILIATION', image_filenames['TABLE_LATEST_INFO_AFFILIATION'])\n",
    "\n",
    "# main contributors\n",
    "\n",
    "filedata = filedata.replace('CHART_LATEST_COMMITS_MAIN_CONTRIBUTORS', image_filenames['CHART_LATEST_COMMITS_MAIN_CONTRIBUTORS'])\n",
    "filedata = filedata.replace('CHART_LATEST_LOC_MAIN_CONTRIBUTORS', image_filenames['CHART_LATEST_LOC_MAIN_CONTRIBUTORS'])\n",
    "\n",
    "filedata = filedata.replace('PIE_LATEST_LOC_MAIN_CONTRIBUTORS', image_filenames['PIE_LATEST_LOC_MAIN_CONTRIBUTORS'])\n",
    "filedata = filedata.replace('PIE_LATEST_COMMITS_MAIN_CONTRIBUTORS', image_filenames['PIE_LATEST_COMMITS_MAIN_CONTRIBUTORS'])\n",
    "\n",
    "filedata = filedata.replace('TABLE_CONTRIBUTORS_STATS_LATEST', image_filenames['TABLE_CONTRIBUTORS_STATS_LATEST'])\n",
    "\n",
    "# timeline \n",
    "filedata = filedata.replace('TIMELINE_LATEST_COMMITS_ALL_CORE', image_filenames['TIMELINE_LATEST_COMMITS_ALL_CORE'])\n",
    "filedata = filedata.replace('TIMELINE_COMMITS_ALL_LATEST', image_filenames['TIMELINE_COMMITS_ALL_LATEST'])\n",
    "\n",
    "# Write the file out again\n",
    "filename = \"report_\" + repository_name + \"_\" + today + \".md\"\n",
    "\n",
    "\n",
    "with open(filename, 'w') as file:\n",
    "  file.write(filedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0478237-1532-448b-ba9b-ce48153e1be5",
   "metadata": {},
   "source": [
    "## Generating Authorship Form\n",
    "\n",
    "Now generate a simple form with first a table listing all the contributors and for each\n",
    "- the number of commits (for the full project)\n",
    "- the number of lines added (for the full project)\n",
    "- the percentage of commits for this author\n",
    "- the percentage of LoC added for this author\n",
    "- Wether this author is considered a main contributor\n",
    "- the number of lines in the (latest) version considered and its percentage\n",
    "\n",
    "Then another table is added with the names of the main contributors, and a column to fill out by the main authors with the respective percentage of contribution in the version considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957717f-ce24-44e6-8c51-41128022cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare the dataframe to generate the authorship form\n",
    "\n",
    "today = str(date.today())\n",
    "\n",
    "# copy basinc info\n",
    "new_df = name_sum_df[['NAME', 'Commits', 'LoC add']].copy()\n",
    "sorted_new_df = new_df.sort_values(by='Commits', ascending=False)\n",
    "\n",
    "# compute percentages\n",
    "total_commit = sorted_new_df['Commits'].sum()\n",
    "sorted_new_df['% Commit'] = ((sorted_new_df['Commits'] / total_commit) * 100).round(1)\n",
    "total_locadd = sorted_new_df['LoC add'].sum()\n",
    "sorted_new_df['% LoC add'] = ((sorted_new_df['LoC add'] / total_locadd) * 100).round(0)\n",
    "\n",
    "# add main contributor flag\n",
    "sorted_new_df['Main contrib'] = sorted_new_df['NAME'].apply(lambda name: 'YES' if name in major_contributors else '')\n",
    "\n",
    "# add info for latest version\n",
    "sorted_new_df = sorted_new_df.merge(latest_name_sum_df[['NAME', 'LoC']], left_on='NAME', right_on='NAME', how='left')\n",
    "sorted_new_df.fillna({'LoC': 0}, inplace=True)\n",
    "sorted_new_df.rename(columns={\"LoC\": \"Latest LoC\"}, inplace=True)\n",
    "sorted_new_df['Latest LoC'] = sorted_new_df['Latest LoC'].astype('int64')\n",
    "total_latestloc = sorted_new_df['Latest LoC'].sum()\n",
    "sorted_new_df['% Latest LoC'] = ((sorted_new_df['Latest LoC'] / total_latestloc) * 100).round(0)\n",
    "\n",
    "\n",
    "## now load the template and generate the tables\n",
    "filedata = None\n",
    "\n",
    "# Read in the template file\n",
    "with open('./data/authorship_form_template.md', 'r') as file:\n",
    "  filedata = file.read()\n",
    "\n",
    "# Replace configuration strings\n",
    "filedata = filedata.replace('PROJECT_NAME', repository_name)\n",
    "filedata = filedata.replace('ORGANIZATION', organisation)\n",
    "\n",
    "filedata = filedata.replace('LATEST_COMMIT_SHA', str(most_recent_commit['sha']))\n",
    "filedata = filedata.replace('LATEST_COMMIT_DATE', str(most_recent_commit['DATE']))\n",
    "\n",
    "filedata = filedata.replace('LOCAL_REPO_COMMIT_SHA', str(local_repo_commit_sha))\n",
    "filedata = filedata.replace('LOCAL_REPO_COMMIT_DATE', str(local_repo_commit_date))\n",
    "\n",
    "# replace tables\n",
    "\n",
    "filedata = filedata.replace('CONTRIBUTORS_TABLE', getContributorsTable(sorted_new_df) )\n",
    "filedata = filedata.replace('AUTHORSHIP_TABLE', getAuthorshipTable(major_contributors) )\n",
    "\n",
    "# Write the file out again\n",
    "filename = \"authorship_form_\" + repository_name + \"_\" + today + \".md\"\n",
    "\n",
    "with open(filename, 'w') as file:\n",
    "  file.write(filedata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b460d9c-51e5-474c-bf29-2c408dc24a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
